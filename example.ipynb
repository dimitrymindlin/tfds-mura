{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChestX-Ray 14 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 02:47:54.313348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.339483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.339774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.340346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-21 02:47:54.342353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.342657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.342958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.856587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.856889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.856900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-11-21 02:47:54.857193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-21 02:47:54.857223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4596 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:2d:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from src.cxr14 import CXR14\n",
    "\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'cx_r14',\n",
    "    split=['train', 'val', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='cx_r14',\n",
      "    full_name='cx_r14/1.1.0',\n",
      "    description=\"\"\"\n",
      "    \"ChestX-ray dataset comprises 112,120 frontal-view X-ray images of 30,805 unique patients with \n",
      "    the text-mined fourteen disease image labels (where each image can have multi-labels), mined \n",
      "    from the associated radiological reports using natural language processing. Fourteen common \n",
      "    thoracic pathologies include Atelectasis, Consolidation, Infiltration, Pneumothorax, Edema, \n",
      "    Emphysema, Fibrosis, Effusion, Pneumonia, Pleural_thickening, Cardiomegaly, Nodule, Mass and \n",
      "    Hernia, which is an extension of the 8 common disease patterns listed in our CVPR2017 paper. \n",
      "    Note that original radiology reports (associated with these chest x-ray studies) are not \n",
      "    meant to be publicly shared for many reasons. The text-mined disease labels are expected to \n",
      "    have accuracy >90%.\"\n",
      "    \"\"\",\n",
      "    homepage='https://nihcc.app.box.com/v/ChestXray-NIHCC',\n",
      "    data_path='/home/tmarkmann/tensorflow_datasets/cx_r14/1.1.0',\n",
      "    download_size=41.98 GiB,\n",
      "    dataset_size=41.97 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
      "        'label': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=2)),\n",
      "        'name': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=1518, num_shards=8>,\n",
      "        'train': <SplitInfo num_examples=104266, num_shards=512>,\n",
      "        'val': <SplitInfo num_examples=6336, num_shards=32>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/WangPLLBS17,\n",
      "      author    = {Xiaosong Wang and\n",
      "                   Yifan Peng and\n",
      "                   Le Lu and\n",
      "                   Zhiyong Lu and\n",
      "                   Mohammadhadi Bagheri and\n",
      "                   Ronald M. Summers},\n",
      "      title     = {ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on\n",
      "                   Weakly-Supervised Classification and Localization of Common Thorax\n",
      "                   Diseases},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1705.02315},\n",
      "      year      = {2017},\n",
      "      url       = {http://arxiv.org/abs/1705.02315},\n",
      "      eprinttype = {arXiv},\n",
      "      eprint    = {1705.02315},\n",
      "      timestamp = {Thu, 03 Oct 2019 13:13:22 +0200},\n",
      "      biburl    = {https://dblp.org/rec/journals/corr/WangPLLBS17.bib},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n",
      "{'class_weights': [{'0': 0.1032743176107264, '1': 0.8967256823892736}, {'0': 0.024590950070013235, '1': 0.9754090499299868}, {'0': 0.11874436537318013, '1': 0.8812556346268199}, {'0': 0.17674026048759903, '1': 0.823259739512401}, {'0': 0.05132066061803464, '1': 0.9486793393819654}, {'0': 0.05654767613603667, '1': 0.9434523238639633}, {'0': 0.012736654326434312, '1': 0.9872633456735657}, {'0': 0.04782958970325897, '1': 0.952170410296741}, {'0': 0.04120230947768208, '1': 0.9587976905223179}, {'0': 0.020505246197226323, '1': 0.9794947538027736}, {'0': 0.022826232904302458, '1': 0.9771737670956976}, {'0': 0.015076822741833388, '1': 0.9849231772581666}, {'0': 0.030201599754474135, '1': 0.9697984002455259}, {'0': 0.002004488519747569, '1': 0.9979955114802525}]}\n"
     ]
    }
   ],
   "source": [
    "print(ds_info)\n",
    "print(ds_info.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_img(image, label):\n",
    "  image = tf.image.resize(image, [224, 224])\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    preproc_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#ds_train = ds_train.shuffle(buffer_size=1000)\n",
    "ds_train = ds_train.batch(8)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    preproc_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(8)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.benchmark(ds_train, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#tfds.show_examples(ds_train, ds_info)\n",
    "def show(image, label):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(np.array2string(label.numpy(), separator=','))\n",
    "  plt.axis('off')\n",
    "   \n",
    "for image, label in ds_train.take(1).unbatch():\n",
    "  show(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(14, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.AUC(curve='ROC',multi_label=True, num_labels=14, from_logits=False)],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ae5caee86a5aefbff32a210a73713acdbea1626cf32a67df5a6d933973ff9a4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
